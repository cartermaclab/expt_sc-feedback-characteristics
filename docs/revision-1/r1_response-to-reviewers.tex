% Taken from https://github.com/mschroen/review_response_letter
% GNU General Public License v3.0

\documentclass[final]{article}

\usepackage[includeheadfoot,top=20mm, bottom=20mm, footskip=2.5cm]{geometry}

% Typography
\usepackage[T1]{fontenc}
\usepackage{times}
%\usepackage{mathptmx} % math also in times font
\usepackage{amssymb,amsmath}
\usepackage{microtype}
\usepackage[utf8]{inputenc}

% Misc
\usepackage{graphicx}
\usepackage[hidelinks]{hyperref} %textopdfstring from pandoc
\usepackage{soul} % Highlight using \hl{}

% Table

\usepackage{adjustbox} % center large tables across textwidth by surrounding tabular with \begin{adjustbox}{center}
\renewcommand{\arraystretch}{1.5} % enlarge spacing between rows
\usepackage{caption}
\captionsetup[table]{skip=10pt} % enlarge spacing between caption and table

% Section styles

\usepackage{titlesec}
\titleformat{\section}{\normalfont\large}{\makebox[0pt][r]{\bf \thesection.\hspace{4mm}}}{0em}{\bfseries}
\titleformat{\subsection}{\normalfont}{\makebox[0pt][r]{\bf \thesubsection.\hspace{4mm}}}{0em}{\bfseries}
\titlespacing{\subsection}{0em}{1em}{-0.3em} % left before after

% Paragraph styles

\setlength{\parskip}{0.6\baselineskip}%
\setlength{\parindent}{0pt}%

% Quotation styles

\usepackage{framed}
\let\oldquote=\quote
\let\endoldquote=\endquote
\renewenvironment{quote}{\begin{fquote}\advance\leftmargini -2.4em\begin{oldquote}}{\end{oldquote}\end{fquote}}

% \usepackage{xcolor}
\newenvironment{fquote}
  {\def\FrameCommand{
	\fboxsep=0.6em % box to text padding
	\fcolorbox{black}{white}}%
	% the "2" can be changed to make the box smaller
    \MakeFramed {\advance\hsize-2\width \FrameRestore}
    \begin{minipage}{\linewidth}
  }
  {\end{minipage}\endMakeFramed}

% Table styles

\let\oldtabular=\tabular
\let\endoldtabular=\endtabular
\renewenvironment{tabular}[1]{\begin{adjustbox}{center}\begin{oldtabular}{#1}}{\end{oldtabular}\end{adjustbox}}


% Shortcuts

%% Let textbf be both, bold and italic
%\DeclareTextFontCommand{\textbf}{\bfseries\em}

%% Add RC and AR to the left of a paragraph
%\def\RC{\makebox[0pt][r]{\bf RC:\hspace{4mm}}}
%\def\AR{\makebox[0pt][r]{AR:\hspace{4mm}}}

%% Define that \RC and \AR should start and format the whole paragraph
\usepackage{suffix}
\long\def\RC#1\par{\makebox[0pt][r]{\bf RC:\hspace{4mm}}{\bf #1}\par\makebox[0pt][r]{AR:\hspace{10pt}}} %\RC
\WithSuffix\long\def\RC*#1\par{{\bf #1}\par} %\RC*
% \long\def\AR#1\par{\makebox[0pt][r]{AR:\hspace{10pt}}#1\par} %\AR
\WithSuffix\long\def\AR*#1\par{#1\par} %\AR*


%%%
%DIF PREAMBLE EXTENSION ADDED BY LATEXDIFF
%DIF UNDERLINE PREAMBLE %DIF PREAMBLE
\RequirePackage[normalem]{ulem} %DIF PREAMBLE
\RequirePackage{color} %DIF PREAMBLE
\definecolor{offred}{rgb}{0.867, 0.153, 0.153} %DIF PREAMBLE
\definecolor{offblue}{rgb}{0.0705882352941176, 0.168627450980392, 0.717647058823529} %DIF PREAMBLE
\providecommand{\DIFdel}[1]{{\protect\color{offred}\sout{#1}}} %DIF PREAMBLE
\providecommand{\DIFadd}[1]{{\protect\color{offblue}\uwave{#1}}} %DIF PREAMBLE
%DIF SAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddbegin}{} %DIF PREAMBLE
\providecommand{\DIFaddend}{} %DIF PREAMBLE
\providecommand{\DIFdelbegin}{} %DIF PREAMBLE
\providecommand{\DIFdelend}{} %DIF PREAMBLE
%DIF FLOATSAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddFL}[1]{\DIFadd{#1}} %DIF PREAMBLE
\providecommand{\DIFdelFL}[1]{\DIFdel{#1}} %DIF PREAMBLE
\providecommand{\DIFaddbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFaddendFL}{} %DIF PREAMBLE
\providecommand{\DIFdelbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFdelendFL}{} %DIF PREAMBLE
%DIF END PREAMBLE EXTENSION ADDED BY LATEXDIFF

% Fix pandoc related tight-list error
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

% Add task difficulty and assignment commands from https://github.com/cdc08x/letter-2-reviewers-LaTeX-template
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{ifdraft}

\newcommand{\TaskEstimationBox}[2]{%
\ifoptiondraft{\parbox{1.0\linewidth}{\hfill \hfill {\colorbox{#2}{\color{White} \textbf{#1}}}}}%
{}%
}
%
\def\WorkInProgress {\TaskEstimationBox{Work in progress}{Cyan}}
\def\AlmostDone {\TaskEstimationBox{Almost there}{NavyBlue}}
\def\Done {\TaskEstimationBox{Done}{Blue}}
%
\def\NotEstimated {\TaskEstimationBox{Effort not estimated}{Gray}}
\def\Easy {\TaskEstimationBox{Feasible}{ForestGreen}}
\def\Medium {\TaskEstimationBox{Medium effort}{Orange}}
\def\TimeConsuming {\TaskEstimationBox{Time-consuming}{Bittersweet}}
\def\Hard {\TaskEstimationBox{Infeasible}{Black}}
%
\newcommand{\Assignment}[1]{
%
\ifoptiondraft{%
\vspace{.25\baselineskip} \parbox{1.0\linewidth}{\hfill \hfill \vspace{.25\baselineskip} \normalfont{Assignment:} \normalfont{\textbf{#1}}}%
}{}%
}


  \usepackage[sfdefault,condensed]{roboto}
  \usepackage[T1]{fontenc}


\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1 \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces\fi
  % set entry spacing
  \ifnum #2 > 0
  \setlength{\parskip}{#2\baselineskip}
  \fi
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\begin{document}

{\Large\bf Author response to reviews of}\\[1em]
Manuscript PBR-BR-22-135\\ \\
{\Large Exercising choice over feedback schedules during practice is not advantageous for motor learning}\\[1em]
{Laura St.~Germain, Brad McKay, Andrew Poskus, Allison Williams, Olena Leshchyshen, Sherry Feldman, Joshua G.A. Cashaback \& Michael J. Carter}\\
{submitted to \it Psychonomic Bulletin \& Review }\\
\hrule

\hfill {\bfseries RC:} \textbf{\textit{Reviewer Comment}}\(\quad\) AR: Author Response \(\quad\square\) Manuscript text

\vspace{2em}

Melody Wiseheart, PhD\\
Action Editor, \emph{Psychonomic Bulletin \& Review}

Dear Dr.~Wiseheart,

Thank you for overseeing the review of our manuscript for publication in \emph{Psychonomic Bulletin \& Review}. We appreciate the positive and helpful comments from the Reviewers. Below we provide our point-by-point response (in normal font) to the Reviewers' comments (in \textbf{\emph{bold-italic}}). All substantial changes in the revised manuscript are included in this response letter (in a text box) and appear in \textcolor{blue}{blue} text in the revised manuscript.

Based on comments from all of the Reviewers, we have made our rationale for Experiment 2 more clear in the Introduction. Although the Reviewers made suggestions ranging from combining the two experiments to removing Experiment 2 altogether, we elected to keep it as Experiment 2. Doing so ensures transparency in our reporting practices as our decision to conduct Experiment 2 was made after we had analyzed the data for Experiment 1. Additionally, it is important to not censor null results in this area of motor learning research given the recent meta-analysis on this topic revealed the supposed self-controlled learning advantage resulted from publication bias rather than being a real effect (McKay, Yantha, Hussien, Carter, \& Ste-Marie, in-press). Reviewer 3 made several suggestions for additional analyses; however, we did not include some of them in the revision. Our primary reason for this decision was that the analysis suggestions were about understanding the information-processing explanation of self-controlled learning advantages. Yet, a key discussion point and conclusion based on our experiments is that there is no self-controlled learning advantage; a conclusion that is consistent with the McKay et al. (in-press) meta-analysis and several recent well-powered (and often pre-registered) experiments. We contend contextualizing our results within this current information negates the usefulness of additional analyses related to the information-processing (or motivational) perspective. We elaborate on these decisions in the point-by-point reply.

I would like to draw your attention to a change in the revised submission regarding our Supplementary documents. In our revision, the sensitivity analyses are now Supplementary A (were B in the original submission) and the error estimation data are now Supplementary B (were A in the original submission). To incorporate suggestions from the Reviewers, we have added Supplementary C which contains information related to the equivalence analyses on the psychological data. Thank you again for considering our work and overseeing the review process.

Sincerely,

Michael J. Carter

\Done

\hypertarget{reviewer-1}{%
\section{Reviewer \#1}\label{reviewer-1}}

\RC{\emph{The authors present a well-designed investigation into self-control of feedback effects on motor skill learning. With N=228 participants assigned to self-controlled or yoked groups (crossed with feedback of differing quality: binary, graded, continuous), this is the largest study to date on the topic that I am aware of, and well-powered to test the a priori hypotheses. On the whole, I think the study is methodologically sound and of great interest to the motor learning community. That said, I do have some concerns about the structure of the manuscript, the use of equivalence tests, the interpretation of some of the data, which I detail below.}}

Thank you for the positive comments about our manuscript.

\Done

\RC{\emph{Validity of "Experiment 2". Given the lack of a learning effect in Experiment 2, I am not sure what this experiment really adds to the literature, nor do I think the self-control effect should be included in meta-analytic estimates moving forward (e.g., in this paper on p. 17, g=0.05, or in other future papers). In essence, the self-control of feedback is thought to moderate the learning effect, but with binary feedback there was no learning effect to begin with. Thus, it would be erroneous to include the null-effect of self-controlled feedback from that experiment when really there was simply no learning effect to moderate. I appreciate the authors reporting this experiment for completeness, but I think it's data should be removed from the equivalence testing section and the Discussion updated accordingly.}}

We agree that the lack of an improvement in performance during practice is unfortunate in Experiment 2. Despite this, we do think these results contribute to the literature. Our goal in the present project was to critically test between the information-processing and motivational (i.e., OPTIMAL theory) accounts of the (supposed) self-controlled learning advantage. After we finished analyzing the data from Experiment 1, it became clear that a second experiment was necessary where the feedback provided to participants would not generate an error signal, which occurs with both error and graded feedback (i.e., both of these provide information about how to correct the error). So binary feedback paired with choice (or no-choice) would be an even stronger test of the two perspectives than that in Experiment 1. From the information-processing perspective, you'd expect no performance advantage of having choice over feedback in practice, retention, or transfer because the information in the binary feedback will be poor at reducing uncertainties about performance outcomes. In contrast, from the motivational perspective (OPTIMAL theory) you'd expect a performance advantage of having choice over feedback in practice, retention, and transfer because the benefits arise from being given the opportunity to exercise choice. Thus, the lack of 1) an improvement in practice and 2) a learning effect in retention and transfer is consistent with the information-processing perspective. However, we do not interpret this as support for the information-processing perspective over the motivational view given the putative self-controlled learning advantage seems to be the result of publication bias rather than a real effect (McKay et al., in-press). We make note of this in a footnote on page 22. As such, any in-depth discussions about whether the information-processing or OPTIMAL theory is correct seem unwarranted. Based on your concerns, we have updated the Introduction (see below) to be more clear about our rationale and the value of Experiment 2.

\begin{quote}
Introduction (Page 4 line 91 continued on page 5 lines 92-100):

To dissociate between the motivational and information-processing accounts of the self-controlled learning advantage, we manipulated the amount of information participants in choice and yoked (i.e., no-choice) groups experienced with their feedback schedule during acqusition of a novel motor task. In Experiment 1, participants received error or graded feedback to assess how high and moderate levels of informational value impact the self-controlled learning advantage. Given both error and graded feedback provide salient information about how to correct one's behavior relative to the task goal (i.e., both generate an error signal), in Experiment 2 we provided participants with binary feedback. As binary feedback is devoid of information about the necessary change to improve one's behavior (i.e., does not generate an error signal), we could better isolate the motivational nature of choice to test between the two explanations for the self-controlled learning advantage.
\end{quote}

Critically, we believe it is vital to report the combined estimate to combat publication bias, especially given the meta-analytic information that has begun to emerge revealing the putative self-controlled learning advantage is the result of publication bias rather than a real effect (McKay et al., in-press). We have kept the combined estimate and still focus on it in our Discussion; however, we now include in the Results section a separate estimate for each Experiment for the interested reader.

\begin{quote}
Results (Page 19 Lines 349-352 continued on page 20 lines 353-355):

Next, random effects meta-analyses were conducted on the retention test data\textsuperscript{4} to generate a summary point estimate and 90\% confidence intervals (CI) with Experiments 1 and 2 combined and also separate. The overall estimated effect when combining both experiments\} was \emph{g} = .05 (favoring self-controlled) and 90\% CI {[}-.12, .23{]}. The overall estimated effect for Experiment 1 was \emph{g} = .03 (favoring self-controlled) and 90\% CI {[}-.19, .25{]}. For Experiment 2, it was \emph{g} = .09 (favoring self-controlled) and 90\% CI {[}-.19, .37{]}.
\end{quote}

\Done

\RC{\emph{It is not clear to me why Experiment 2 is a separate experiment? This is the same task with a different type of feedback, right? Thus, I assume that this reflect the schedule of recruitment and all of the subjects in Experiment 2 were enrolled later. While not wrong to call it Experiment 2, I think it would be more parsimonious to have one experiment with 3 feedback types and then simply explain any cohort effects in the methods.}}

Yes, you are correct about the task, different type of feedback, and recruitment of participants for Experiment 2. We maintain referring to them as separate experiments as presenting it as a single experiment would pose some methodological problems. First, our decision to conduct Experiment 2 was conditional on observing the results of Experiment 1 (as mentioned in our above response), which would undermine the assumption of independence between observations. Second, random assignment to receive either error or graded feedback was done for participants in the self-controlled and yoked groups in Experiment 1. With the timing of the collection of these experiments, participants in Experiment 2 could not have been assigned to receive either error or graded feedback and Experiment 1 participants could not have been randomly assigned to receive binary feedback. Lastly, our \emph{a priori} sample size calculation was not based on a design that included all groups in a single experiment.

\Done

\RC{\emph{Assignment of subjects to groups. From the authors' description, it sounds like ALL yoked participants were enrolled after ALL self-controlled participants in a given feedback condition. Albeit minor, this introduces a confound in the timing of the two groups. Something to consider for future studies would be a blocked assignment stratified by factors like gender age or handedness (e.g., the first right handed female to come into the lab gets self-control of a randomly assigned feedback type... the NEXT right handed female to come into the lab gets yoked to the same feedback schedule and type, etc). This would make the assignment order a bit more complicated, but would reduce the temporal disparity between the groups.}}

Yes, all participants in the self-controlled groups were collected before the yoked participants. We acknowledge in the original submission (and now Page 7 Lines 158-160 in the revised manuscript) that ``this is typical in the self-controlled learning literature as the self-controlled participants' self-selected feedback schedules are required for providing feedback to the participants in the yoked (i.e., control) groups.'' We do agree that different assignment strategies could have been used; however, our decision was to follow the typical procedure for this area of research.

\Done

\RC{\emph{Lack of reporting for psychological variables. I might have missed it as there are many results presented, but could the authors report the (non-significant?) results of the self-control manipulation? The authors currently report the significant effects of Time and Feedback, but the effect of Self Control seems more theoretically relevant although non-significant.}}

We now report the effect of Choice in all analyses in the Results section. The effect of Choice was always non-significant.

\Done

\RC{\emph{Lack of equivalence tests for motivational variables. In the same way it is theoretically relevant to do equivalence tests at retention, it seems like it would be important to do equivalence tests for the different motivational variables as well?}}

We agree these would be theoretically relevant and have included them in Supplementary C.

\Done

\hypertarget{review-2}{%
\section{Review \#2}\label{review-2}}

\RC{\emph{This manuscript reports a study that attempted to test different causal explanations for the self-controlled learning advantage. The explanations could not be examined because the experiment failed to find a self-controlled learning advantage. The study adds to a growing body of evidence which has failed to replicate the self-controlled learning advantage in the motor skills domain. Given the rigor with which the study was conducted and analyzed, the findings make an important contribution to the literature.}

\emph{I do not have any major concerns with the manuscript, though I may have called in to question the decision to limit practice to 72 trials had a self-controlled learning advantage been discovered. The reason is that Magill and Wood (1986) did not find a benefit of quantitative (error) versus qualitative (graded) feedback on a multi-movement timing task until the second half of practice. During the first half, learners derived the same benefit from quantitative and qualitative feedback. Consequently, it is not clear whether the amount of practice in the current experiment would have provided a fair test of the information processing account of the putative self-controlled learning advantage given that the informational value of quantitative feedback seems to increase with practice. Of course, that point is moot given the current findings.}}

Thank you for the encouraging and positive comments about our manuscript. The amount of practice is an interesting point given past motor learning research looking at this variable. We discuss the Magill and Wood paper below with another comment of yours.

\RC{\emph{In the abstract, the task is described as a rapid reaching task with spatial and temporal timing goals. I would not describe this task as a reaching task. I think it would be more appropriate to simply say “… while learning a planar upper limb movement with spatial and timing goals.” Note that it is referred to as a rapid aiming task on page 4, l. 25.}}

We have removed all reference to the task as a reaching task and now describe it as a ``novel motor task'' in the abstract.

\Done

\RC{\emph{I recommend stating that error and graded feedback have also been referred to as quantitative and qualitative feedback (e.g., Magill \& Wood, 1986) when you introduce error and graded feedback.}}

We have incorporated your suggestion as a footnote in the revised manuscript when we introduce error and graded feedback on page 3.

\Done

\RC{\emph{The description of the sample size estimation on page 5, l. 23 specifies that “groups = 2.” Shouldn’t the number of groups be 4?}}

Thank you for catching this typo. We have corrected it to say groups = 4 on page 6.

\Done

\RC{\emph{Comparisons were done to determine if error estimation improved with practice and whether the groups differed in terms of error estimation abilities at different stages of learning. However, it would be interesting to report if the participants who were asked to estimate during the pretest performed better in acquisition, retention and transfer than the participants who were not asked to estimate during the pretest. I realize this comparison was not an original purpose of the experiment, however, reporting this information would add value in my opinion.}}

We have added this analysis to Supplementary B and there were no significant main effects or interactions.

\Done

\RC{\emph{I understand the rationale for restricting the participants in the choice groups to 24 trials, however, it would be prudent to raise the possibility in the discussion that limiting choice in this way may have attenuated the self-controlled learning advantage.}}

We do not think this restriction contributed to our lack of a self-controlled learning advantage. Based on a recent meta-analysis (McKay et al., in-press), we believe we did not find a self-controlled learning advantage because it either does not exist or is an extremely small effect. However, to your point earlier self-controlled feedback research actually found that limiting the number of choice opportunities does not negatively impact learning (Patterson, Carter, \& Sanli, 2011) and can even lead to superior learning (Hansen, Pfeiffer, \& Patterson, 2011). Based on the conclusions of the self-controlled learning meta-analysis, we elected to not discuss this possibility and instead maintain the focus on our results being consistent with the meta-analytic estimates and conclusions of McKay et al. (in-press) regarding the self-controlled learning advantage being either a non-real effect or an extremely small effect.

\Done

\RC{\emph{I am not certain the findings from Experiment 2 offer much insight into self-controlled learning given that learners were not able to learn anything with this type of feedback. However, for the sake of thoroughness, Experiment 2 deserves to be described in the manuscript. I recommend reporting the number of “hits” in Experiment 2 to give readers a sense of the number of occasions learners received some sort of positive reinforcement. I think it would also be helpful to report the number of hits in Experiment 1 to potentially bolster the argument for the proposed disassociation between the informational and motivational impacts of knowledge of results.}}

Based on your comment (and a comment by Reviewer 1), we have updated the introduction to more clearly describe our rationale for and the value of Experiment 2. The lack of a performance improvement in practice is consistent with the information-processing perspective as the binary feedback would not be effective at reducing uncertainties about performance outcomes. As such, under such conditions you would expect the results we saw. However, the lack of improvement is inconsistent with a motivational perspective wherein having choice itself is the cause for any performance and learning benefits. We do not interpret this as support for the information-processing perspective over the motivational view given the putative self-controlled learning advantage seems to be the result of publication bias rather than a real effect (McKay et al., in-press). We make note of this in a footnote on page 22.

\begin{quote}
Introduction (Page 4 line 91 continued on page 5 lines 92-100):

To dissociate between the motivational and information-processing accounts of the self-controlled learning advantage, we manipulated the amount of information participants in choice and yoked (i.e., no-choice) groups experienced with their feedback schedule during acqusition of a novel motor task. In Experiment 1, participants received error or graded feedback to assess how high and moderate levels of informational value impact the self-controlled learning advantage. Given both error and graded feedback provide salient information about how to correct one's behavior relative to the task goal (i.e., both generate an error signal), in Experiment 2 we provided participants with binary feedback. As binary feedback is devoid of information about the necessary change to improve one's behavior (i.e., does not generate an error signal), we could better isolate the motivational nature of choice to test between the two explanations for the self-controlled learning advantage.
\end{quote}

Thank you for the suggestion of including the number of hits in both experiments. We have included this information in Table 2 (page 18) in the revised manuscript and we also make reference to it in the Discussion.

\begin{quote}
Discussion (Page 23 Lines 447-450):

The number of ``hits'' for the spatial and timing goals were both quite low for all groups. Although this may have also impacted perceptions of competence, the relatively low ``hit'' rate did not seem to differentially impact intrinsic motivation as self-reported levels were quite similar for all groups.
\end{quote}

\Done

\RC{\emph{Were the questions from the Intrinsic Motivation Inventory modified in any way and were the perceived autonomy questions exactly the same as those used earlier?}}

We modified the questions for the IMI subscales so it referenced ``the motor task'' when participants were asked the various questions. An example for the perceived competence subscale is: ``I think I am pretty good at this motor task''. An example for the interest/enjoyment is: ``This motor task was fun to do''. The perceived autonomy questions (e.g., ``There is not much opportunity for my to exercise choices during my practice session'') were the same across both experiments and used in previous work (e.g., Carter \& Ste-Marie, 2017; St. Germain et al., 2022). We have included a copy of all the questions used for perceived competence, intrinsic motivation, and perceived autonomy in the public repository for this experiment in a directory called ``materials''. We make a specific note of the availability of the questionnaires in a footnote on page 11.

\Done

\RC{\emph{Do you have any explanation for why the graded feedback group continued to improve during practice after the error feedback group had plateaued? This is a curious finding, as one would expect just the opposite based on Magill and Wood (1986).}}

It was an interesting result that Magill and Wood (1986) did not find a difference in feedback types until the second half of practice with 100 trials; although there are some considerable differences between their experiment and ours. First, they used a motor task that required six movements and varying timing goals compared to our single movement with a timing and spatial goal. So there could be some differences due to complexity or difficulty of the to-be-learned motor task. Second, Magill and Wood report that they did not find an interaction between Block and Feedback type until they strayed from their \emph{a priori} analysis plan and excluded a block after observing their data. This interaction was also only found in one of their three performance outcome variables. For these reasons, we think their result must be interpreted cautiously. However, we do think it would be of value for future studies to further probe this potential interaction between amount of practice and different characteristics of the feedback provided to the learners. In terms of the significant Feedback x Block interaction we found for the timing goal in Experiment 1, the improvements in the Graded feedback groups after block 2 were quite minimal. In Figure 2B, all four groups are very similar from blocks 4 to 6. A potential explanation for this could be that the high informational value of the error feedback could have led to those participants making short-term maladaptive corrections to their responses (Salmoni, Schmidt, \& Walter, 1984).

\Done

\hypertarget{reviewer-3}{%
\section{Reviewer \#3}\label{reviewer-3}}

\RC{\emph{This paper reports two experiments (total n=228) on how exercising choice influences motor learning of a reaching task with spatial and timing goals. Participants practiced either with choice over feedback requests or under no-choice, yoked feedback conditions. In Experiment 1, two forms of knowledge of results feedback were tested (error feedback or graded feedback) and in Experiment 2, binary feedback was provided. Behavioral performance, error estimation, and psychosocial data were collected. Whereas the error and graded feedback conditions supported skill acquisition, the binary feedback did not yield significant improvements from pre-testing to retention. Across both experiments, there was no evidence that the opportunity to exert self-control enhanced learning compared to the no-choice groups.}

\emph{In my opinion, the presented manuscript is well-written and contributes a well-powered study to the current debate surrounding self-controlled learning. However, I think a stronger rationale for Experiment 2 (binary feedback) should be provided. It is not clear to me why this manipulation was presented as a standalone experiment rather than as additional feedback condition in Experiment 1, and perhaps it is not necessary to include the binary feedback groups in the manuscript at all. Additionally, as the manuscript discusses both the OPTIMAL and information-processing perspectives as potential explanations for self-controlled learning advantages, I feel that the inclusion of further analyses regarding participants’ feedback requests could help to better understand the mechanisms underpinning self-controlled learning. Overall, I generally believe that this paper is publishable pending some relatively minor revisions. I have noted page and line numbers (according to the authors’ submitted version) along with my more specific points below.}}

Thank you for the positive comments about our manuscript. In line with comments from the other two Reviewers, we have updated the Introduction to more clearly explain our rationale for and the value of Experiment 2. In short, after we had analyzed the data from Experiment 1, we realized that a second experiment was required where participants received a type of feedback that would have a very low informational value for how to correct one's behaviour (i.e., would not generate an error signal). This is why binary feedback was chosen for Experiment 1 because both error and graded feedback generate an error signal as both provide information about how to change one's behaviour. As such, we feel Experiment 2 was a stronger test of the information-processing and motivational perspectives. From the information-processing view, you'd expect no performance advantages of having choice over binary feedback in any experimental phase whereas from the motivational view, you'd still expect performance advantages in practice, retention, and transfer because these benefits arise out of having choice. Additionally, keeping the results of Experiment 2 in the manuscript is important for meta-analytic reasons, especially given the recent self-controlled learning meta-analysis found that the putative self-controlled learning advantage is the result of publication bias rather than a true effect (McKay et al., in-press).

\begin{quote}
Introduction (Page 4 line 91 continued on page 5 lines 92-100):

To dissociate between the motivational and information-processing accounts of the self-controlled learning advantage, we manipulated the amount of information participants in choice and yoked (i.e., no-choice) groups experienced with their feedback schedule during acqusition of a novel motor task. In Experiment 1, participants received error or graded feedback to assess how high and moderate levels of informational value impact the self-controlled learning advantage. Given both error and graded feedback provide salient information about how to correct one's behavior relative to the task goal (i.e., both generate an error signal), in Experiment 2 we provided participants with binary feedback. As binary feedback is devoid of information about the necessary change to improve one's behavior (i.e., does not generate an error signal), we could better isolate the motivational nature of choice to test between the two explanations for the self-controlled learning advantage.
\end{quote}

\Done

\RC{\emph{p. 7, lines 16-17: “Additionally, half of the participants in each group were randomly selected to estimate their performance on the spatial and timing goals after each trial in the pre-test.” Please provide more detail on how participants provided their estimations (e.g., manual vs. verbal responses, spatial and/or timing estimations)}}

We have clarified that participants made their estimations verbally on pages 7 (line 168) and 11 (line 210).

\Done

\RC{\emph{p. 9, lines 1-2: “Following a 2000 ms feedback delay interval, the feedback decision prompt was presented for the self-controlled groups.” How did participants indicate whether they did or did not want feedback? (e.g., manual vs. verbal response?) Although this is nicely illustrated in Figure 1, it would be helpful to also include in the text that participants were made aware of how many feedback trials remained}}

We have clarified that participants made their feedback request verbally on page 9 (line 208) and in the Figure 1 caption (page 10). We have also included the information about the remaining feedback trials in the text on page 9 (lines 205-206).

\Done

\RC{\emph{p. 8, lines 17-18: “Graded feedback for the spatial goal was provided as “too short” if performance was < 40 degrees (or 60 degrees in transfer)”. I think it’s confusing to include the ’60 degrees in transfer’ here (as well as on page 9, lines 18-20) if there was no feedback provided in transfer (according to p. 7, lines 13-14: “No feedback about motor performance was provided in pre-test, retention, or transfer”).}}

Thank you for catching this. We have removed this confusing information.

\Done

\RC{\emph{p. 9, lines 9-12: “The perceived competence and task interest and enjoyment questions were from the Intrinsic Motivation Inventory and the perceived autonomy questions were used in earlier work”. Just to clarify, the perceived autonomy questions are not the same as the perceived choice subscale in the IMI? If this is a customized scale, please note if the specific items are available in a previous publication, and if not, consider including them in the supplementary materials.}}

The perceived autonomy questions we used are not the perceived choice subscale of the IMI. You are correct that they are a customized scale that we have used in the past (e.g., Carter \& Ste-Marie, 2017; St. Germain et al., 2022). We have also added the questions we used for all questionnaires to the public repository for this project in the directory ``materials''.

\Done

\RC{\emph{Is the finding that exercising choice did not impact perceptions of autonomy compared to yoked groups unusual? Is there a different/perhaps more sensitive way to assess perceptions of autonomy?}}

It is actually quite common to not find an effect of choice over some practice variable like one's feedback schedule on measures of perceived autonomy (e.g., Barros, Yantha, Carter, Hussien, \& Ste-Marie, 2019; Carter \& Ste-Marie, 2017; McKay \& Ste-Marie, 2022; Ste-Marie, Vertes, Law, \& Rymal, 2013). It was actually only very recently that some studies found higher perceptions of autonomy (e.g., McKay \& Ste-Marie, 2020; St. Germain et al., 2022) in those participants given choice versus those not given the same choice opportunities. A key difference is both of those experiments had even larger sample sizes per group than what we had in the present work. For instance, St.~Germain et al.~(2022) had 50 participants per group. Thus, we think this highlights that the impact of being given choice over a practice variable has a rather small effect on perceived autonomy and requires larger sample sizes to reliably detect. As a side note, our perceived autonomy questions are those used in the St.~Germain et al.~paper, which found an effect favouring choice on perceived autonomy.

\Done

\RC{\emph{I felt there were a number of additional analyses that could be conducted to help provide a more fulsome story. For example:}}

Thank you for the following suggestions. In short, we did not perform any analyses regarding the distribution of feedback requests or how feedback requests related to performance. Both of these have been reported in several previous papers investigating self-controlled feedback schedules. We provide more details regarding our decision below when we respond to each analysis suggestion independently. We did, however, include details regarding the number of ``hits'' as this was something that Reviewer 2 also raised.

\Done

\RC{\emph{a. What was the distribution of feedback requests throughout acquisition? (e.g., did participants generally choose to fade their feedback? or perhaps are there early vs. late feedback requesters?)}}

Our main reason for not analyzing the distribution of feedback requests or early verus late requesters is these are not things we manipulated in our design. Thus, these analyses would be post-hoc and non-causal. As such, we do not think that would provide any new insight beyond what has already been reported in earlier self-controlled feedback research: sometimes participants seem to create faded request schedules (e.g., Chiviacowsky \& Wulf, 2002; Janelle, Barba, Frehlich, Tennant, \& Cauraugh, 1997) and sometimes schedules stay relatively consistent (e.g., Patterson \& Carter, 2010). Additionally, a recent meta-analysis (McKay et al., 2022) did not find evidence for several feedback scheduling hypotheses: no evidence 1) that faded schedules are more effective than non-faded, 2) that performance-contingent or bandwidth schedules are more effective than fixed schedules, and 3) that feedback frequency does not have consistent effects. For these reasons, we elected to not conduct these analyses and instead keep our discussion more focused on the fact that our results are consistent with the recent self-controlled learning meta-analysis suggesting this supposed effect is likely non-existent and instead was the result of publication bias.

\Done

\RC{\emph{b. How did feedback requests relate to learners’ performance? (e.g., did feedback requests tend to follow relatively good vs. bad trials?). This seems particularly important to address with reference to the information-processing explanation of self-controlled learning advantages.}}

We did not query participants on their reasons why or why not feedback was requested during practice. Without knowing this information for each participant, it is not possible to know whether any relation to relatively good or relatively bad trials was strategic or coincidental. Given such an analysis would also be post-hoc and non-causal, we also do not think this analysis would provide new insight beyond that already reported in earlier self-controlled feedback experiments that have used multiple-choice questionnaires (e.g., Carter \& Patterson, 2012; Chiviacowsky \& Wulf, 2002; Patterson \& Carter, 2010; Patterson et al., 2011) or open-ended questions (e.g., Carter, Rathwell, \& Ste-Marie, 2016; Laughlin et al., 2015). Similar to above, not including these unplanned analyses allows us to remain focused on our main conclusion that there is a lot of evidence emerging that strongly suggests the supposed self-controlled learning advantage is not a replicable or real effect.

\Done

\RC{\emph{c. How often did participants actually "hit" the target? It seems that the success criteria were quite strict - can you be expected to “acquire/retain” a skill you haven’t successfully performed? Could the potential unlikelihood of success/limited expectancies for success have undermined potential motivational aspects of self-control?}}

We have added information about the number of ``hits'' in Table 2 (Page 18) of the revised manuscript based on your comment and that from Reviewer 2. Interestingly, the ``hit'' rate was low in both experiments and for all groups. Although the low success rates seem to have impacted perceptions of competence, particularly for those that received graded and binary feedback, the graded feedback groups improved their performance during practice, and retention and transfer were better than pre-test levels. Further, the graded feedback groups' ratings for perceived competence were numerically similar to those reported by the participants in Experiment 2 with binary feedback. Additionally, self-reported intrinsic motivation was numerically similar in all experimental groups. As such, we do not think the low ``hit'' rates in the present experiments undermined any potential motivational influences of self-controlled feedback schedules. We also now make reference to the hit data in the Discussion.

\begin{quote}
Discussion (Page 23 Lines 447-450):

The number of ``hits'' for the spatial and timing goals were both quite low for all groups. Although this may have also impacted perceptions of competence, the relatively low ``hit'' rate did not seem to differentially impact intrinsic motivation as self-reported levels were quite similar for all groups.
\end{quote}

\Done

\RC{\emph{p. 18, lines 1-3: “...argued that self-controlled feedback is effective because it provides the opportunity to request feedback in a performance dependent way that reduces uncertainty about movement outcomes relative to task goals”. Yes – as noted above, it would be helpful to understand whether these participants requested feedback in a performance dependent fashion}}

In line with our response above, we did not query participants on their reasons for requesting feedback. The idea that self-controlled feedback is effective because it reduces uncertainty about movement outcomes emerged from early work by Chiviacowsky and Wulf (2005) that showed a self-controlled feedback schedule was only effective if the feedback decision was made after and not before one's performance. Carter et al.~(2014) extended this work with a group that made their feedback decision before a trial but could then change their mind after a trial. Thus, the key idea behind requesting feedback in a performance dependent way to reduce uncertainty is about making the decision \emph{after} one's movement, which was the case for all self-controlled groups in the present experiment. But consistent with earlier responses and our stance in the manuscript, we do not think the self-controlled learning advantage is a real effect based on recent experiments with large samples (and often pre-registered) and the meta-analysis by McKay et al. (in-press). As such, analyses and discussions surrounding the information-processing explanation or the motivational (i.e., OPTIMAL theory) view seem moot. We instead contend that contextualizing our results within these larger, and often pre-registered, experiments and the McKay et al.~meta-analysis is the more critical discussion point.

\Done

\RC{\emph{p. 19, lines 19-21: “Similarly, self-controlled feedback schedules did not enhance error estimation skills (see Supplementary A) [...], inconsistent with the information-processing perspective.” Similar to above, I think we need to know more about participants feedback choices to consider why error estimation skills did not improve and how this speaks to the information-processing perspective}}

To clarify, error estimation skills did improve from pre-test to retention and transfer for the subset of participants who estimated during pre-test in Experiment 1. We did not find that error estimation was enhanced in the choice groups compared to the yoked groups. We have made this more clear in the revised manuscript.

\begin{quote}
Discussion (Page 22 Lines 420-421)

Similarly, self-controlled feedback schedules did not enhance error estimation skills compared to yoked schedules (see \textbf{Supplementary B}) and choice did not interact with feedback characteristics, inconsistent with the information-processing perspective.
\end{quote}

Similar to our above comments, such a finding is consistent with the idea that there is no self-controlled learning advantage to explain from an information-processing or motivational view in motor learning (McKay et al., in-press).

\Done

\RC{\emph{p. 20, lines 6-10: “Additionally, we used a strict criteria with binary feedback where any outcome other than zero error was considered a miss. Thus, binary feedback may be more effective when paired with a tolerance zone such as that used in the bandwidth technique” Agreed... As mentioned earlier, please indicate what the rate of success was in this group and consider whether this group can be integrated into Experiment 1 or removed}}

As mentioned above with respect to your earlier comment, we have added this information in the revised manuscript in Table 2 on page 18.

\Done

\hypertarget{references}{%
\section{References}\label{references}}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-barros2019}{}}%
Barros, J. A. C., Yantha, Z. D., Carter, M. J., Hussien, J., \& Ste-Marie, D. M. (2019). Examining the impact of error estimation on the effects of self-controlled feedback. \emph{Human Movement Science}, \emph{63}, 182--198. \url{https://doi.org/10.1016/j.humov.2018.12.002}

\leavevmode\vadjust pre{\hypertarget{ref-carter2012}{}}%
Carter, M. J., \& Patterson, J. T. (2012). Self-controlled knowledge of results: {Age-related} differences in motor learning, strategies, and error detection. \emph{Human Movement Science}, \emph{31}(6), 1459--1472. \url{https://doi.org/10.1016/j.humov.2012.07.008}

\leavevmode\vadjust pre{\hypertarget{ref-carter2016}{}}%
Carter, M. J., Rathwell, S., \& Ste-Marie, D. M. (2016). Motor skill retention is modulated by strategy choice during self-controlled knowledge of results schedules. \emph{Journal of Motor Learning and Development}, \emph{4}, 100--115. \url{https://doi.org/10.1123/jmld.2015-0023}

\leavevmode\vadjust pre{\hypertarget{ref-carter2017b}{}}%
Carter, M. J., \& Ste-Marie, D. M. (2017). Not all choices are created equal: {Task}-relevant choices enhance motor learning compared to task-irrelevant choices. \emph{Psychonomic Bulletin \& Review}, \emph{24}(6), 1879--1888. \url{https://doi.org/10.3758/s13423-017-1250-7}

\leavevmode\vadjust pre{\hypertarget{ref-chiviacowsky2002}{}}%
Chiviacowsky, S., \& Wulf, G. (2002). Self-controlled feedback: Does it enhance learning because performers get feedback when they need it? \emph{Research Quarterly for Exercise and Sport}, \emph{73}(4), 408--415.

\leavevmode\vadjust pre{\hypertarget{ref-chiviacowsky2005}{}}%
Chiviacowsky, S., \& Wulf, G. (2005). Self-controlled feedback is effective if it is based on the learner's performance. \emph{Research Quarterly for Exercise and Sport}, \emph{76}(1), 42--48. \url{https://doi.org/10.1080/02701367.2005.10599260}

\leavevmode\vadjust pre{\hypertarget{ref-hansen2011}{}}%
Hansen, S., Pfeiffer, J., \& Patterson, J. T. (2011). Self-control of feedback during motor learning: Accounting for the absolute amount of feedback using a yoked group with self-control over feedback. \emph{Journal of Motor Behavior}, \emph{43}(2), 113--119.

\leavevmode\vadjust pre{\hypertarget{ref-janelle1997}{}}%
Janelle, C. M., Barba, D. A., Frehlich, S. G., Tennant, L. K., \& Cauraugh, J. H. (1997). Maximizing performance feedback effectiveness through videotape replay and a self-controlled learning environment. \emph{Research Quarterly for Exercise and Sport}, \emph{68}(4), 269--279.

\leavevmode\vadjust pre{\hypertarget{ref-laughlin2015}{}}%
Laughlin, D. D., Fairbrother, J. T., Wrisberg, C. A., Alami, A., Fisher, L. A., \& Huck, S. W. (2015). Self-control behaviors during the learning of a cascade juggling task. \emph{Human Movement Science}, \emph{41}, 9--19. \url{https://doi.org/10.1016/j.humov.2015.02.002}

\leavevmode\vadjust pre{\hypertarget{ref-magill1986}{}}%
Magill, R. A., \& Wood, C. A. (1986). Knowledge of results precision as a learning variable in motor skill acquisition. \emph{Research Quarterly for Exercise and Sport}, \emph{57}(2), 170--173. \url{https://doi.org/10.1080/02701367.1986.10762195}

\leavevmode\vadjust pre{\hypertarget{ref-mckay2022}{}}%
McKay, B., Hussien, J., Vinh, M.-A., Mir-Orefice, A., Brooks, H., \& Ste-Marie, D. M. (2022). Meta-analysis of the reduced relative feedback frequency effect on motor learning and performance. \emph{Psychology of Sport and Exercise}, 102165.

\leavevmode\vadjust pre{\hypertarget{ref-mckay2020a}{}}%
McKay, B., \& Ste-Marie, D. M. (2020). Autonomy support and reduced feedback frequency have trivial effects on learning and performance of a golf putting task. \emph{Human Movement Science}, \emph{71}, 102612. \url{https://doi.org/10.1016/j.humov.2020.102612}

\leavevmode\vadjust pre{\hypertarget{ref-mckay2020b}{}}%
McKay, B., \& Ste-Marie, D. M. (2022). Autonomy support via instructionally irrelevant choice not beneficial for motor performance or learning. \emph{Research Quarterly for Exercise and Sport}, \emph{93}, 64--76. \url{https://doi.org/10.1080/02701367.2020.1795056}

\leavevmode\vadjust pre{\hypertarget{ref-mckay2021}{}}%
McKay, B., Yantha, Z. D., Hussien, J., Carter, M. J., \& Ste-Marie, D. M. (in-press). Meta-analytic findings in the self-controlled motor learning literature: {Underpowered}, biased, and lacking evidential value. \emph{Meta-Psychology}. In-press. \url{https://doi.org/10.31234/osf.io/8d3nb}

\leavevmode\vadjust pre{\hypertarget{ref-patterson2010}{}}%
Patterson, J. T., \& Carter, M. (2010). Learner regulated knowledge of results during the acquisition of multiple timing goals. \emph{Human Movement Science}, \emph{29}(2), 214--227.

\leavevmode\vadjust pre{\hypertarget{ref-patterson2011}{}}%
Patterson, J. T., Carter, M., \& Sanli, E. (2011). Decreasing the proportion of self-control trials during the acquisition period does not compromise the learning advantages in a self-controlled context. \emph{Research Quarterly for Exercise and Sport}, \emph{82}(4), 624--633.

\leavevmode\vadjust pre{\hypertarget{ref-salmoni1984}{}}%
Salmoni, A. W., Schmidt, R. A., \& Walter, C. B. (1984). Knowledge of results and motor learning: A review and critical reappraisal. \emph{Psychological Bulletin}, \emph{95}(3), 355--386. \url{https://doi.org/10.1037/0033-2909.95.3.355}

\leavevmode\vadjust pre{\hypertarget{ref-stgermain2022}{}}%
St. Germain, L., Williams, A., Balbaa, N., Poskus, A., Leshchyshen, O., Lohse, K. R., \& Carter, M. J. (2022). Increased perceptions of autonomy through choice fail to enhance motor skill retention. \emph{Journal of Experimental Psychology: Human Perception and Performance}, \emph{48}(4), 370--379. \url{https://doi.org/10.1037/xhp0000992}

\leavevmode\vadjust pre{\hypertarget{ref-stemarie2013}{}}%
Ste-Marie, D. M., Vertes, K. A., Law, B., \& Rymal, A. M. (2013). Learner-controlled self-observation is advantageous for motor skill acquisition. \emph{Frontiers in Psychology}, \emph{3}, 556.

\end{CSLReferences}


\end{document}\grid
